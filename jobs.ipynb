{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#source: https://python.gotrained.com/scrapy-tutorial-web-scraping-craigslist/\n",
    "import scrapy\n",
    "from scrapy import Request\n",
    " \n",
    "\n",
    "class JobsSpider(scrapy.Spider):\n",
    "    name = 'jobs'    #Name of the spider\n",
    "    allowed_domains = ['https://seattle.craigslist.org/search/hea?']     #List of domains the spider is allowed to scrape\n",
    "    start_urls = ['https://seattle.craigslist.org/search/hea?']   #One of the domains that the spider starts with for crawling\n",
    "\n",
    "#Scrapy adds \"http://\" and an extra '/' to the start_urls. They need to be removed.\n",
    "    \n",
    "    def parse(self, response):\n",
    "        #Extracting several details about \"healthcare\" jobs\n",
    "        jobs = response.xpath('//p[@class=\"result-info\"]')\n",
    "        \n",
    "        #No extract() since we are scrapping all the wrappers from the page\n",
    "        \n",
    "        #response refers to the whole HTML code extracted\n",
    "        #xpath refers to the rules based on which the extraction happens\n",
    "        #'//' means to start extracting from the tag 'p' mentioned after it\n",
    "        #the <p> has <a> tag. Use inspect element on any listing to know more\n",
    "        \n",
    "        for job in jobs:\n",
    "            title = job.xpath('a/text()').extract_first()\n",
    "            #or title = job.xpath('.//a/text()').extract_first()\n",
    "            #to yield more than one element from the wrapper, this technique is preferred    \n",
    "            #consider extracting address and URL from the same wrapper at one shot inside this for loop\n",
    "            address = job.xpath('span[@class=\"result-meta\"]/span[@class=\"result-hood\"]/text()').extract_first(\"\")[2:-1]\n",
    "            \n",
    "            #the above statement goes to span, extracts text() from result-hood, slices string\n",
    "            #extract_first(\"\") is essential - when slicing returns \"None\", then the result is defaulted to empty string\n",
    "            #Used for cases when location is NULL in the advertisement\n",
    "            \n",
    "            relative_url = job.xpath('a/@href').extract_first()\n",
    "            absolute_url = response.urljoin(relative_url)\n",
    "            #Or use absolute_url = \"https://newyork.craigslist.org\" + relative_url\n",
    "            yield{'URL':absolute_url, 'Title':title, 'Address':address}\n",
    "        \n",
    "        \n",
    "        relative_next_url = response.xpath('//a[@class=\"button next\"]/@href').extract_first(\"\")\n",
    "        absolute_next_url = response.urljoin(relative_next_url)\n",
    "        if(relative_next_url != \"\"):\n",
    "            yield Request(absolute_next_url, callback=self.parse, dont_filter=True)\n",
    "            \n",
    "    def parse_page(self, response)\n",
    "        url = response.meta.get('URL')\n",
    "        title = response.meta.get('Title')\n",
    "        address = response.meta.get('Address')\n",
    "        \n",
    "        description = ''.join(line for line in response.xpath('//*[@id = \"postingbody\"]/text()').extract())\n",
    "        \n",
    "        compensation = response.xpath('//p[@class = \"attrgroup\"]/b/text()')[0].extract()\n",
    "        \n",
    "        employment_type = response.xpath('//p[@class = \"attrgroup\"]/b/text()')[1].extract()\n",
    "        \n",
    "        yield{'URL': url, 'Title': title, 'Address':address, 'Description':description, 'Compensation':compensation, 'Employment Type':employment_type}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
